import cv2
import numpy as np
import sys
import os
import time
import tensorflow as tf  # âœ… ç”¨äº TFLite æ¨ç†
import blazepalm_utils as but

# ======================
# åŸºæœ¬é…ç½®
# ======================
IMAGE_PATH = 'thumbs_up.jpg'
SAVE_IMAGE_PATH = 'output.png'

TFLITE_MODEL = 'palm_detection_full.tflite'  # âœ… æ”¹ä¸º TFLite æ¨¡å‹è·¯å¾„

IMAGE_HEIGHT = 192
IMAGE_WIDTH = 192
ANCHOR_PATH = 'anchors_192.npy'
CHANNEL_FIRST = False


# ======================
# å·¥å…·å‡½æ•°
# ======================
def imread(filename, flags=cv2.IMREAD_COLOR):
    if not os.path.isfile(filename):
        sys.exit(f"âŒ æ–‡ä»¶ä¸å­˜åœ¨: {filename}")
    data = np.fromfile(filename, np.int8)
    img = cv2.imdecode(data, flags)
    return img


def get_savepath(arg_path, src_path, prefix='', post_fix='_res', ext=None):
    if '.' in arg_path:
        arg_base, arg_ext = os.path.splitext(arg_path)
        new_ext = arg_ext if ext is None else ext
        new_path = arg_base + new_ext
    else:
        src_base, src_ext = os.path.splitext(os.path.basename(src_path))
        new_ext = src_ext if ext is None else ext
        new_path = os.path.join(arg_path, prefix + src_base + post_fix + new_ext)
    dirname = os.path.dirname(new_path)
    if dirname != "":
        os.makedirs(dirname, exist_ok=True)
    return new_path


def display_result(img, detections, with_keypoints=True):
    if detections.ndim == 1:
        detections = np.expand_dims(detections, axis=0)

    n_keypoints = detections.shape[1] // 2 - 2
    for i in range(detections.shape[0]):
        ymin, xmin, ymax, xmax = detections[i, :4].astype(int)
        img = cv2.rectangle(img, (xmin, ymin), (xmax, ymax), (255, 0, 0), 1)
        if with_keypoints:
            for k in range(n_keypoints):
                kp_x = int(detections[i, 4 + k * 2])
                kp_y = int(detections[i, 4 + k * 2 + 1])
                cv2.circle(img, (kp_x, kp_y), 2, (0, 0, 255), thickness=2)
    return img


# ======================
# ä¸»æ¨ç†å‡½æ•°
# ======================
def recognize_from_image():
    # ======================
    # åŠ è½½è¾“å…¥å›¾åƒ
    # ======================
    src_img = imread(IMAGE_PATH)
    img256, _, scale, pad = but.resize_pad(src_img[:, :, ::-1], IMAGE_WIDTH)
    input_data = img256.astype('float32') / 255.0
    input_data = np.expand_dims(input_data, axis=0)  # [1, 192, 192, 3]

    print("âœ… å›¾åƒé¢„å¤„ç†å®Œæˆ, shape =", input_data.shape)

    # ======================
    # åŠ è½½ TFLite æ¨¡å‹
    # ======================
    print(f"ğŸ” åŠ è½½ TFLite æ¨¡å‹: {TFLITE_MODEL}")
    interpreter = tf.lite.Interpreter(model_path=TFLITE_MODEL)
    interpreter.allocate_tensors()

    input_details = interpreter.get_input_details()
    output_details = interpreter.get_output_details()

    print("ğŸ“¥ è¾“å…¥å¼ é‡ä¿¡æ¯:", input_details)
    print("ğŸ“¤ è¾“å‡ºå¼ é‡ä¿¡æ¯:")
    for i, od in enumerate(output_details):
        print(f"  Output[{i}]: name={od['name']}, shape={od['shape']}")

    # ======================
    # æ¨¡å‹æ¨ç†
    # ======================
    print("ğŸš€ å¼€å§‹æ¨ç†...")
    interpreter.set_tensor(input_details[0]['index'], input_data)
    interpreter.invoke()

    outputs = [interpreter.get_tensor(od['index']) for od in output_details]
    print(f"âœ… æ¨ç†å®Œæˆï¼Œè·å¾— {len(outputs)} ä¸ªè¾“å‡ºå¼ é‡")

    # ======================
    # åå¤„ç†
    # ======================
    normalized_detections = but.postprocess(outputs, anchor_path=ANCHOR_PATH, resolution=IMAGE_WIDTH)[0]
    detections = but.denormalize_detections(normalized_detections, scale, pad, resolution=IMAGE_WIDTH)

    # ======================
    # æ˜¾ç¤ºä¸ä¿å­˜ç»“æœ
    # ======================
    result_img = display_result(src_img, detections)
    savepath = get_savepath(SAVE_IMAGE_PATH, "./")
    cv2.imwrite(savepath, result_img)
    print(f'ğŸ’¾ ç»“æœå·²ä¿å­˜è‡³: {savepath}')


def main():
    recognize_from_image()


if __name__ == '__main__':
    main()
